# Quantifying Metacognition in LLM Ensembles

Welcome to the **Metacognitive State Vector (MSV)** project website.  
This research explores **metacognition** and **self-awareness** in ensembles of Large Language Models (LLMs).
---

## ðŸ“° News

- **Jan 2026** â€“ Draft website for the *Quantifying Metacognition in LLMs* project launched.
- **Dec 2025** â€“ Paper submission to CIKM 2025.
- **Nov 2025** â€“ Google Cloud Research Grant received.
- (Add more past updates here)

!!! info "Research Overview"
    **Institution:** Fitchburg State University  
    **PI:** Dr. Ricky J. Sethi  
    **Collaborators:** Dr. Hefei Qiu, Dr. Charles Courchaine, Joshua Iacoboni   
    **Conference:** ACM CIKM 2025 - Seoul, South Korea

# Introduction

The **Quantifying Metacognition in LLMs** project explores how large language models exhibit self-awareness and reasoning under uncertainty using a metacognitive framework.  
This page introduces the motivation and theoretical background for our work, inspired by the dual-process cognitive model and recent advances in LLM ensembles.

## Motivation

Understanding *how* models think about their own reasoning processes provides insight into interpretability, reliability, and generalization.  
Our goal is to develop metrics and representations that quantify metacognitive awareness in artificial systems.

## Core Idea

We build on prior work in cognitive science and AI to model the transition between **System 1 (intuitive reasoning)** and **System 2 (reflective reasoning)** processes within ensembles of LLMs.
